{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ab3543",
   "metadata": {},
   "source": [
    "# Updated version of distance measurement and analysis between macrophages and ECs\n",
    "\n",
    "- New 'shortest distance' code\n",
    "- New 'macs within radius' code\n",
    "- Added randomised control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f852c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LIBRARY\n",
    "import os\n",
    "import glob\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.io import imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.util import invert\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_minimum, threshold_isodata, threshold_triangle, threshold_mean\n",
    "from skimage.filters import threshold_otsu, threshold_li, threshold_yen\n",
    "from skimage.morphology import binary_dilation\n",
    "from scipy.ndimage import binary_erosion\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.filters import gaussian\n",
    "from skimage.morphology import label\n",
    "from skimage.measure import regionprops\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.segmentation import relabel_sequential\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.morphology import remove_small_holes\n",
    "from skimage.morphology import dilation, disk\n",
    "from scipy.ndimage import binary_dilation\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import measure\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "from statistics import mean, stdev\n",
    "import re\n",
    "from natsort import natsorted\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage.morphology import closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3b81b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "filename = 'C:/Users/terez/Documents/Skola/Ludwig-Maximilians_Universitat_Munchen/Research course Moretti lab/Microscopy data etc/EXP6/Macrophages_and_ECs/ImmEpis_EXP6_d3_GFP_cTnT_CD31'\n",
    "pixel_size = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52173b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImmEpis_EXP6_d3_GFP_cTnT_CD31\n"
     ]
    }
   ],
   "source": [
    "## separated for the papermil\n",
    "\n",
    "# filename extract\n",
    "last_folder = os.path.basename(filename)\n",
    "# output folder:\n",
    "output_folder = 'C:/Users/terez/Documents/Skola/Ludwig-Maximilians_Universitat_Munchen/Research course Moretti lab/Microscopy data etc/EXP6/EC_analysis/Distances'\n",
    "\n",
    "# to save masks:\n",
    "# to save masks:\n",
    "\n",
    "folder = f'{filename}/masks_distances'\n",
    "folder1 = f'{filename}/masks_with_nuclei_count'\n",
    "folder2 = f'{filename}/masks_nuclei'\n",
    "os.makedirs(folder1, exist_ok=True)\n",
    "os.makedirs(folder2, exist_ok=True)\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "print(last_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c0dce2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to check: \n",
      " number of 405 images: \t 15, \n",
      " number of 488 images: \t 15,\n",
      " number of 594 images: \t 15, \n",
      " number of 647 images: \t 15\n"
     ]
    }
   ],
   "source": [
    "### LOADING\n",
    "\n",
    "## DAPI in 405 channel:\n",
    "list_of_dapi_files = natsorted(glob.glob(f\"{filename}/*ch00*.tif\"))\n",
    "images_dapi = {}\n",
    "for file in list_of_dapi_files:\n",
    "    img = io.imread(file)\n",
    "    images_dapi[os.path.basename(file)] = img\n",
    "\n",
    "## 488 channel:\n",
    "list_of_488_files = natsorted(glob.glob(f\"{filename}/*ch01*.tif\"))\n",
    "images_488 = {}\n",
    "for file in list_of_488_files:\n",
    "    img = io.imread(file)\n",
    "    images_488[os.path.basename(file)] = img\n",
    "\n",
    "## 594 channel:\n",
    "list_of_594_files = natsorted(glob.glob(f\"{filename}/*ch02*.tif\"))\n",
    "images_594 = {}\n",
    "for file in list_of_594_files:\n",
    "    img = io.imread(file)\n",
    "    images_594[os.path.basename(file)] = img\n",
    "\n",
    "## 647 channel:\n",
    "list_of_647_files = natsorted(glob.glob(f\"{filename}/*ch03*.tif\"))\n",
    "images_647 = {}\n",
    "for file in list_of_647_files:\n",
    "    img = io.imread(file)\n",
    "    images_647[os.path.basename(file)] = img\n",
    "\n",
    "print(f\"to check: \\n number of 405 images: \\t {len(images_dapi)}, \\n number of 488 images: \\t {len(images_488)},\"\n",
    "      f\"\\n number of 594 images: \\t {len(images_594)}, \\n number of 647 images: \\t {len(images_647)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "972633c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nuclei masks: 15\n"
     ]
    }
   ],
   "source": [
    "## Grabbing the cellpose masks from the folder\n",
    "\n",
    "list_of_nuclei_mask_files = natsorted(glob.glob(f\"{folder2}/*.tif\"))\n",
    "nuclei_masks = {}\n",
    "\n",
    "for file in list_of_nuclei_mask_files:\n",
    "    img = io.imread(file)\n",
    "    nuclei_masks[os.path.basename(file)] = img\n",
    "\n",
    "print(f'Number of nuclei masks: {len(nuclei_masks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "569b9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Channel gating\n",
    "\n",
    "tested_image = 'Image 1' #d1_6\n",
    "\n",
    "## testing:\n",
    "# tries all automatic thresholding options for the image \n",
    "# fig, ax = try_all_threshold(blurred_dapi_test, figsize=(6, 12), verbose=False)\n",
    "# plt.show()\n",
    "\n",
    "## DAPI/organoid area:\n",
    "def dapi_analysis(mask):\n",
    "    thresholding = mask > threshold_triangle(mask)\n",
    "    dilated = binary_dilation(thresholding, iterations=100) #dilates the individual nuclei by 100 pixels\n",
    "                                                            #this covers up the holes/spaces in between\n",
    "                                                            #also bridges whatever cavities etc. are present \n",
    "    thresholding_2 = remove_small_holes(dilated, area_threshold=50000) #removes the remaining holes\n",
    "    eroded = binary_erosion(thresholding_2, iterations=80) #erodes the expanded mask back to original size\n",
    "                                                           #basically 'tightens' the mask to better fit the \n",
    "                                                           #organoid\n",
    "    thresholding_3 = remove_small_objects(eroded, min_size=8000) #removes stray nuclei outside of the organoid\n",
    "    blurred = gaussian(thresholding_3, sigma=10) #blurrs the jagged edges\n",
    "    smoothed = blurred > 0.2 #blurring makes the image non-binary, this makes it binary again by selecting\n",
    "                             #the intensities over certain threshold (in this case everything over 20%)\n",
    "\n",
    "    return(smoothed)\n",
    "\n",
    "\n",
    "## 488\n",
    "def analysis_488(image,object_min_size):\n",
    "    thresholding_1 = image > threshold_triangle(image) #originaly otsu\n",
    "    thresholding_2 = remove_small_objects(thresholding_1, min_size=object_min_size) #100\n",
    "    return(thresholding_2)\n",
    "\n",
    "def watershed_488(mask):\n",
    "    #new:\n",
    "    distance_transform_488 = ndi.distance_transform_edt(mask)\n",
    "    # Find peaks (likely centers of individual cells)\n",
    "    local_maxi_test = peak_local_max(distance_transform_488, labels=mask, footprint=np.ones((3, 3)), min_distance=30) #originaly 30\n",
    "    local_maxi_test_2 = np.zeros_like(distance_transform_488, dtype=bool)\n",
    "    local_maxi_test_2[tuple(local_maxi_test.T)] = True\n",
    "\n",
    "    # Label the peaks\n",
    "    markers_test = measure.label(local_maxi_test_2)\n",
    "\n",
    "    # watershed\n",
    "    watershed_labels_test = watershed(-distance_transform_488, markers_test, mask=mask)\n",
    "\n",
    "    return(watershed_labels_test)\n",
    "\n",
    "\n",
    "## 647\n",
    "def analysis_647(image):\n",
    "    background = gaussian(image, sigma=50)   # smooth background\n",
    "    normalisation = image - background\n",
    "    normalisation = exposure.rescale_intensity(normalisation, out_range=(0, 1))\n",
    "    thresholding_1 = normalisation > threshold_triangle(normalisation) # originaly triangle / 470\n",
    "    thresholding_2 = remove_small_objects(thresholding_1, min_size=100)\n",
    "\n",
    "    # thresholding_2 = remove_small_objects(thresholding_1,min_size=object_min_size)\n",
    "    # dilated = binary_dilation(thresholding_1, iterations=15)\n",
    "    # thresholding_3 = remove_small_objects(dilated, min_size=100) #originaly 250\n",
    "    # erosion = binary_erosion(thresholding_3, iterations=14)\n",
    "    # blurred = gaussian(erosion, sigma=3) #blurrs the jagged edges\n",
    "    # smoothed = blurred > 0.5\n",
    "    return(thresholding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "138d34be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1\n",
      "Image 2\n",
      "Image 3\n",
      "Image 4\n",
      "Image 5\n",
      "Image 6\n",
      "Image 7\n",
      "Image 8\n",
      "Image 9\n",
      "Image 10\n",
      "Image 11\n",
      "Image 12\n",
      "Image 13\n",
      "Image 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\terez\\AppData\\Local\\Temp\\ipykernel_3088\\4289361689.py:115: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  per_of_unmac_ECs = num_CD31_cells/nearest_distances.count(47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 16\n"
     ]
    }
   ],
   "source": [
    "Image_data_CD31_files = {}\n",
    "Individual_data_CD31_files = {}\n",
    "\n",
    "min_size_488 = 100\n",
    "mac_radius = 13\n",
    "\n",
    "for name,img in images_488.items():\n",
    "\n",
    "    ### CREATION OF INDIVIDUAL IMAGE MASKS:\n",
    "\n",
    "    ## 488\n",
    "    # img_488 = images_488[f'{name_without_last_part}_ch01.tif']\n",
    "    thresholded_488 = analysis_488(img, object_min_size=min_size_488)\n",
    "    watersheded_488 = watershed_488(thresholded_488)\n",
    "    objects_488 = regionprops(watersheded_488,img)\n",
    "\n",
    "    num_macrophages = watersheded_488.max()\n",
    "\n",
    "    #image name extracted:\n",
    "    name_without_last_part = '_'.join(name.split('_')[:-1]) \n",
    "    print(name_without_last_part)\n",
    "\n",
    "    ## DAPI\n",
    "    dapi_mask = nuclei_masks[f'{name_without_last_part}_ch00_mask.tif']\n",
    "    thresholded_405 = dapi_analysis(dapi_mask)\n",
    "    organoid_size = np.sum(thresholded_405)\n",
    "    organoid_size_in_um = organoid_size*(pixel_size**2)\n",
    "\n",
    "\n",
    "    ## 647\n",
    "    img_647 = images_647[f'{name_without_last_part}_ch03.tif']\n",
    "    thresholded_647 = analysis_647(img_647) & thresholded_405\n",
    "    labelled_647 = label(thresholded_647)\n",
    "    objects_647 = regionprops(labelled_647,img_647)\n",
    "\n",
    "    num_CD31_cells = labelled_647.max()\n",
    "\n",
    "    ## fake 488 mask\n",
    "    # this determines where the pixels are positive in the dapi mask:\n",
    "    organoid_coords_2 = np.column_stack(np.where(thresholded_405))\n",
    "    total_points_2 = organoid_coords_2.shape[0]\n",
    "    # this selects random coordinates inside the positive area of the dapi mask that is equal to the number \n",
    "    # of macs detected (approximated since the macs are basically a single mass and not individual cells)\n",
    "    select_indeces_2 = np.random.choice(total_points_2, size=num_macrophages, replace=False)\n",
    "    selected_coords_2 = organoid_coords_2[select_indeces_2]\n",
    "    # create an empty mask\n",
    "    expanded_mask = np.zeros_like(thresholded_405, dtype=bool)\n",
    "    # structuring element\n",
    "    fake_mac = disk(mac_radius)\n",
    "    # new 'fake' mac mask:\n",
    "    seed_mask = np.zeros_like(thresholded_405, dtype=bool)\n",
    "    seed_mask[selected_coords_2[:,0], selected_coords_2[:,1]] = 1\n",
    "    dilated = binary_dilation(seed_mask, fake_mac)\n",
    "    fake_mac_mask = np.logical_and(dilated, thresholded_405)\n",
    "\n",
    "\n",
    "    ### HERE THE ANALYSIS STARTS\n",
    "\n",
    "    number_of_iter = 46 #29.9um\n",
    "\n",
    "    #this is for the real data:\n",
    "    original_areas = []\n",
    "    nearest_distances = []\n",
    "    mac_area_around_EC = []\n",
    "\n",
    "    # this is for the randomised control:\n",
    "    mac_radius = 13\n",
    "    random_original_areas = []\n",
    "    random_nearest_distances = []\n",
    "    random_mac_area_around_EC = []\n",
    "\n",
    "    for obj in objects_647:\n",
    "        \n",
    "        obj_mask = np.zeros_like(thresholded_488, dtype=bool)\n",
    "        obj_mask[tuple(obj.coords.T)] = True\n",
    "\n",
    "        original_area = obj.area*(pixel_size**2)\n",
    "        original_areas.append(original_area)\n",
    "\n",
    "        ## this is for the real data:\n",
    "        #nearest distance:\n",
    "        dilated_obj = obj_mask.copy()\n",
    "\n",
    "        for i in range(1, number_of_iter + 1):\n",
    "            dilated_obj = binary_dilation(dilated_obj, iterations=1)\n",
    "            overlap = np.any(dilated_obj & (thresholded_488>0))\n",
    "            if overlap:\n",
    "                nearest_distances.append(i*pixel_size)\n",
    "                break\n",
    "        else:\n",
    "            nearest_distances.append(number_of_iter+1)\n",
    "\n",
    "        #mac overlap:\n",
    "        dilated_obj_2 = binary_dilation(obj_mask.copy(), iterations=number_of_iter)\n",
    "        mac_area_in_radius = np.sum(thresholded_488 & dilated_obj_2)\n",
    "        mac_area_around_EC.append(mac_area_in_radius*(pixel_size**2))\n",
    "\n",
    "        ##this is for randomised control:\n",
    "        dilated_obj_3 = obj_mask.copy()\n",
    "\n",
    "        for i in range(1, number_of_iter + 1):\n",
    "            dilated_obj_2 = binary_dilation(dilated_obj_3, iterations=1)\n",
    "            overlap = np.any(dilated_obj_3 & (fake_mac_mask>0))\n",
    "            if overlap:\n",
    "                random_nearest_distances.append(i*pixel_size)\n",
    "                break\n",
    "        else:\n",
    "            random_nearest_distances.append(number_of_iter+1)\n",
    "\n",
    "        #mac overlap:\n",
    "        dilated_obj_4 = binary_dilation(obj_mask.copy(), iterations=number_of_iter)\n",
    "        random_mac_area_in_radius = np.sum(fake_mac_mask & dilated_obj_4)\n",
    "        random_mac_area_around_EC.append(random_mac_area_in_radius*(pixel_size**2))\n",
    "\n",
    "    per_of_unmac_ECs = num_CD31_cells/nearest_distances.count(47)\n",
    "    per_of_unmac_ECs_ctrl = num_CD31_cells/random_nearest_distances.count(47)\n",
    "\n",
    "    average_min_dist = mean(nearest_distances)\n",
    "    average_min_dist_ctrl = mean(random_nearest_distances)\n",
    "\n",
    "    average_mac_area = mean(mac_area_around_EC)\n",
    "    average_mac_area_ctrl = mean(random_mac_area_around_EC)\n",
    "\n",
    "    average_CD31_area = mean(original_areas)\n",
    "\n",
    "    Image_data_CD31_files[name_without_last_part] = {\n",
    "        'CD31_number': num_CD31_cells,\n",
    "        'CD31 average area': average_CD31_area,\n",
    "        'Mac number': num_macrophages,\n",
    "        'EC w/o mac [%]': per_of_unmac_ECs,\n",
    "        'EC w/o mac ctrl [%]': per_of_unmac_ECs_ctrl,\n",
    "        'Average min distance [um]': average_min_dist,\n",
    "        'Average min distance ctrl [um]': average_min_dist_ctrl,\n",
    "        'Average mac area in radius [um^2]': average_mac_area,\n",
    "        'Average mac area in radius ctrl [um^2]': average_mac_area_ctrl\n",
    "    }\n",
    "\n",
    "    Individual_data_CD31_files[name_without_last_part] = {\n",
    "        'CD31_areas': original_areas,\n",
    "        'Minimal distances': nearest_distances,\n",
    "        'Minimal distances ctrl': random_nearest_distances,\n",
    "        'Mac area in radius': mac_area_around_EC,\n",
    "        'Mac area in radius ctrl': random_mac_area_around_EC\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9179522",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATAFRAME\n",
    "df_cd31_distances = pd.DataFrame.from_dict(Image_data_CD31_files, orient='index')\n",
    "output_path = f'{output_folder}/{last_folder}_distances.xlsx'\n",
    "df_cd31_distances.to_excel(output_path)\n",
    "\n",
    "# New data frame:\n",
    "# Individual_data_CD31_files_2 = {}\n",
    "\n",
    "# for name, variables in Individual_data_CD31_files.items():\n",
    "#     for var_name, var_list in variables.items():\n",
    "#         flat_key = f'{name}_{var_name}'\n",
    "#         Individual_data_CD31_files_2[flat_key] = var_list\n",
    "# df_individual_distances = pd.DataFrame.from_dict(Individual_data_CD31_files_2,orient='index') #\n",
    "# reversed_df_individual_distances = df_individual_distances.T\n",
    "\n",
    "output_path_2 = f'{output_folder}/{last_folder}_individual_data.xlsx'\n",
    "# reversed_df_individual_distances.to_excel(output_path_2)\n",
    "\n",
    "# reversed_df_individual_distances.head()\n",
    "\n",
    "# v2\n",
    "with pd.ExcelWriter(output_path_2) as writer:\n",
    "    for name,variables in Individual_data_CD31_files.items():\n",
    "        df = pd.DataFrame(variables)\n",
    "        df.to_excel(writer,sheet_name=name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
